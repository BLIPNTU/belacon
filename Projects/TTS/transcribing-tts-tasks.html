<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/belacon/assets/css/just-the-docs-default.css"> <style type="text/css"> .site-nav > .nav-list:nth-child(1):not(.nav-category-list) > .nav-list-item:not(.external):nth-child(3) > .nav-list > .nav-list-item:nth-child(1) > .nav-list > .nav-list-item:nth-child(3) > .nav-list-link { display: block; font-weight: 600; text-decoration: none; background-image: linear-gradient(-90deg, #ebedf5 0%, rgba(235, 237, 245, 0.8) 80%, rgba(235, 237, 245, 0) 100%); } .site-nav > .nav-list:nth-child(1):not(.nav-category-list) > .nav-list-item:not(.passive):nth-child(3) > .nav-list-expander svg, .site-nav > .nav-list:nth-child(1):not(.nav-category-list) > .nav-list-item:not(.passive):nth-child(3) > .nav-list > .nav-list-item:not(.passive):nth-child(1) > .nav-list-expander svg { transform: rotate(-90deg); } .site-nav > .nav-list:nth-child(1):not(.nav-category-list) > .nav-list-item:not(.passive):nth-child(3) > .nav-list, .site-nav > .nav-list:nth-child(1):not(.nav-category-list) > .nav-list-item:not(.passive):nth-child(3) > .nav-list > .nav-list-item:not(.passive):nth-child(1) > .nav-list { display: block; } .site-nav > .nav-category-list > .nav-list-item:not(.passive) > .nav-list-expander svg { transform: rotate(-90deg); } .site-nav > .nav-category-list > .nav-list-item:not(.passive) > .nav-list { display: block; } </style> <script src="/belacon/assets/js/vendor/lunr.min.js"></script> <script src="/belacon/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>Guide to Transcribing Talk Together Study Tasks | BELA Convention</title> <meta name="generator" content="Jekyll v3.8.7" /> <meta property="og:title" content="Guide to Transcribing Talk Together Study Tasks" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="This website contains BELA documentation, developed by researchers at BLIP Lab, Nanyang Technological University, Singapore." /> <meta property="og:description" content="This website contains BELA documentation, developed by researchers at BLIP Lab, Nanyang Technological University, Singapore." /> <link rel="canonical" href="https://blipntu.github.io/belacon/Projects/TTS/transcribing-tts-tasks.html" /> <meta property="og:url" content="https://blipntu.github.io/belacon/Projects/TTS/transcribing-tts-tasks.html" /> <meta property="og:site_name" content="BELA Convention" /> <meta property="og:type" content="website" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="Guide to Transcribing Talk Together Study Tasks" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","description":"This website contains BELA documentation, developed by researchers at BLIP Lab, Nanyang Technological University, Singapore.","headline":"Guide to Transcribing Talk Together Study Tasks","url":"https://blipntu.github.io/belacon/Projects/TTS/transcribing-tts-tasks.html"}</script> <!-- End Jekyll SEO tag --> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/belacon/" class="site-title lh-tight"> BELA Convention </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><a href="/belacon/" class="nav-list-link">Home</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in BELA Manuals category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/belacon/BELA/" class="nav-list-link">BELA Manuals</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Using ELAN category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/belacon/BELA/ELAN/" class="nav-list-link">Using ELAN</a><ul class="nav-list"><li class="nav-list-item"> <a href="/belacon/BELA/ELAN/definitions.html" class="nav-list-link">Definitions</a> </li><li class="nav-list-item"> <a href="/belacon/BELA/ELAN/dependent-tiers.html" class="nav-list-link">Dependent Tiers</a> </li><li class="nav-list-item"> <a href="/belacon/BELA/ELAN/new-elan-page.html" class="nav-list-link">Make a New ELAN File</a> </li><li class="nav-list-item"> <a href="/belacon/BELA/ELAN/transcribing.html" class="nav-list-link">Transcribing</a> </li><li class="nav-list-item"> <a href="/belacon/BELA/ELAN/controlled-vocabs.html" class="nav-list-link">Controlled Vocabularies</a> </li><li class="nav-list-item"> <a href="/belacon/BELA/ELAN/transcribing-dependent-tiers.html" class="nav-list-link">Transcribing Dependent Tiers</a> </li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in BELA Convention category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/belacon/BELA/convention/" class="nav-list-link">BELA Convention</a><ul class="nav-list"><li class="nav-list-item"> <a href="/belacon/BELA/convention/privacy.html" class="nav-list-link">Privacy Matters</a> </li><li class="nav-list-item"> <a href="/belacon/BELA/convention/tier-guide.html" class="nav-list-link">A Guide to All Your Tiers</a> </li><li class="nav-list-item"> <a href="/belacon/BELA/convention/language-tag-list.html" class="nav-list-link">Language Tag List</a> </li><li class="nav-list-item"> <a href="/belacon/BELA/convention/special-characters.html" class="nav-list-link">List of special codes</a> </li><li class="nav-list-item"> <a href="/belacon/BELA/convention/baby-babbling.html" class="nav-list-link">Guide to Baby Babbling</a> </li><li class="nav-list-item"> <a href="/belacon/BELA/convention/text-transcription.html" class="nav-list-link">Quick Tips/General Transcription Guide/Resources</a> </li><li class="nav-list-item"> <a href="/belacon/BELA/convention/nonverbal-transcription.html" class="nav-list-link">Non-verbal Transcription</a> </li></ul></li><li class="nav-list-item"><a href="/belacon/BELA/faq.html" class="nav-list-link">FAQs</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Projects category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/belacon/Projects/" class="nav-list-link">Projects</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Talk-Together Study category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/belacon/Projects/TTS/" class="nav-list-link">Talk-Together Study</a><ul class="nav-list"><li class="nav-list-item"> <a href="/belacon/Projects/TTS/transcription-template.html" class="nav-list-link">Transcription Template</a> </li><li class="nav-list-item"> <a href="/belacon/Projects/TTS/file-naming-tts.html" class="nav-list-link">File Naming Procedures (Talk Together Study)</a> </li><li class="nav-list-item"> <a href="/belacon/Projects/TTS/transcribing-tts-tasks.html" class="nav-list-link">Guide to Transcribing Talk Together Study Tasks</a> </li><li class="nav-list-item"> <a href="/belacon/Projects/TTS/checking-transcriptions.html" class="nav-list-link">Guide to Checking Transcriptions</a> </li><li class="nav-list-item"> <a href="/belacon/Projects/TTS/transcription-log.html" class="nav-list-link">Transcription Log & Dictionary Overview</a> </li></ul></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Data Policy Guide category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/belacon/RDMGuide/" class="nav-list-link">Data Policy Guide</a><ul class="nav-list"><li class="nav-list-item"><a href="/belacon/RDMGuide/rationale.html" class="nav-list-link">Rationale</a></li><li class="nav-list-item"><a href="/belacon/RDMGuide/essenstials.html" class="nav-list-link">Essentials</a></li></ul></li><li class="nav-list-item"><a href="/belacon/changelog/" class="nav-list-link">Changelog</a></li><li class="nav-list-item"><a href="/belacon/about/" class="nav-list-link">About</a></li></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search BELA Convention" aria-label="Search BELA Convention" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> </div> <div class="main-content-wrap"> <nav aria-label="Breadcrumb" class="breadcrumb-nav"> <ol class="breadcrumb-nav-list"> <li class="breadcrumb-nav-list-item"><a href="/belacon/Projects/">Projects</a></li> <li class="breadcrumb-nav-list-item"><a href="/belacon/Projects/TTS/">Talk-Together Study</a></li> <li class="breadcrumb-nav-list-item"><span>Guide to Transcribing Talk Together Study Tasks</span></li> </ol> </nav> <div id="main-content" class="main-content"> <main> <h1 id="transcribing-tasks-from-the-talk-together-study-tts"> <a href="#transcribing-tasks-from-the-talk-together-study-tts" class="anchor-heading" aria-labelledby="transcribing-tasks-from-the-talk-together-study-tts"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Transcribing tasks from the Talk Together Study (TTS) </h1> <p><em>Last updated: Sept 25th 2023</em></p> <p>This page is our protocol how to approach transcribing data from the various Talk Together Study activities.</p> <p>Please refer to the previous pages for specific guidance on <a href="/belacon/BELA/convention/special-characters.html">transcription conventions</a>, <a href="/belacon/BELA/convention/language-tag-list.html">language tags</a>, the <a href="/belacon/BELA/convention/tier-guide.html">tiers needed</a>, or the <a href="/belacon/Projects/TTS/transcription-template.html">ELAN template</a>.</p> <p>The playlist of our video tutorials geared towards transcribing data from the Talk Together Study can be found <a href="https://www.youtube.com/playlist?list=PL88Oq1V_lmS7yzhEBuc9oYezHg0o_KXDM">here</a>. <strong>However, please cross-reference the wiki for the most up-to-date protocol. Any changes to the protocol since the creation of the videos have been noted in the video description.</strong></p> <p>Additionally, watch our video regarding <a href="https://youtu.be/DjmT-zPXPp4">things to keep in mind</a> during the transcription process.</p> <p>Do not hesitate to contact a full-time staff member should you have questions.</p> <h2 id="contents"> <a href="#contents" class="anchor-heading" aria-labelledby="contents"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Contents </h2> <ul> <li><a href="#transcribing-voicemail-game-picture-cards-recordings">Transcribing Voicemail Game Picture Cards Recordings</a></li> <li><a href="#transcribing-voicemail-game-talk-prompts-recordings">Transcribing Voicemail Game Talk Prompts Recordings</a></li> <li><a href="#transcribing-voicemail-game-green-grass-park-recordings">Transcribing Voicemail Game Green Grass Park Recordings</a></li> <li><a href="#transcribing-video-call-storytime-phase-1-recordings">Transcribing Video Call Storytime Phase/Timepoint 1 Recordings</a></li> <li><a href="#transcribing-video-call-storytime-phase-2-recordings">Transcribing Video Call Storytime Phase/Timepoint 2 Recordings</a></li> <li><a href="#transcribing-video-call-storytime-phase-3-recordings">Transcribing Video Call Storytime Phase/Timepoint 3 Recordings</a></li> </ul><hr /> <h2 id="transcribing-voicemail-game-picture-cards-recordings"> <a href="#transcribing-voicemail-game-picture-cards-recordings" class="anchor-heading" aria-labelledby="transcribing-voicemail-game-picture-cards-recordings"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Transcribing Voicemail Game Picture Cards Recordings </h2> <p><strong><em>For a video demonstration of transcribing a picture card recording, please watch <a href="https://youtu.be/821do8_P_oY">this video</a> from our playlist.</em></strong></p> <p>As part of the Voicemail Game in this study, participants will record an audio recording of their responses to three different Voicemail Game activities in English and also in their other preferred language (Mandarin, Malay, or Tamil). The first activity of the Voicemail Game is the Picture Cards activity. We may also refer to this as the Vowel Triangle activity.</p> <p>The picture cards include a picture and an associated “target” word. Participants will read the individual words one-by-one in English and their other preferred language language. The recording should only contain one adult speaker.</p> <p>Visit <a href="https://blogs.ntu.edu.sg/blip/baby/talktogetherstudy/audio/picturecards/">this page</a> to see all the picture cards sorted by language.</p> <ol> <li> <p>Import the audio file (.wav) <em>and</em> the template file (.etf) into ELAN. Refer to the “Transcription Template” section of the wiki on instructions on how to handle the template subsequent to importing it.</p> </li> <li> <p>Go to “File” and click “Save” or “Save As” like a normal document. The file should be named according to the file naming conventions outlined on the wiki. You can also set an automatic backup of the file by going to “File” &gt; “Automatic Backup”. Choose a time interval between 1 to 30 minutes that suits your preference. Note: the backup file will be saved with the extension <code class="highlighter-rouge">*.eaf.001</code>.</p> </li> <li> <p>In order to see the hierarchical relationship between the dependent tiers, right click on the tier sidebar &gt; Sort Tiers &gt; Sort by Hierarchy.</p> </li> <li> <p>Listen to the audio file in full before you begin transcribing. Mentally note what languages are being spoken. Note any muffled parts or parts where all speech become indecipherable. Information on how to deal with these parts can be found under Frequently Asked Questions (FAQ).</p> </li> <li> <p>Edit the tier attributes to replace placeholder participant codes with accurate participant ID codes for all the participants present in the recording. This should be done on all the present participant’s primary and secondary tiers.(e.g. if the participant ID is <code class="highlighter-rouge">P1234TT</code> and the mother is the only speaker in this recording, the Mother code <code class="highlighter-rouge">MPXXXXTT</code> should be edited to <code class="highlighter-rouge">MP1234TT</code> on all the Mother primary and secondary tiers). <strong>DO NOT DELETE UNUSED TIERS. Right click on the tier panel and hide them if they are getting in your way</strong></p> </li> <li> <p>Adjust the vertical zoom (right click on the waveform &gt; Vertical Zoom &gt; adjust the %) and horizontal zoom (adjust the slider at the bottom right of the ELAN screen) to help you see the waveform clearly.</p> </li> <li>Put on your headphones and begin transcribing the audio file. <ul> <li>Isolate and annotate the individual target words on the <code class="highlighter-rouge">Utterance</code>, <code class="highlighter-rouge">Chunk</code>, <code class="highlighter-rouge">Language</code>, and relevant Target_Language (i.e., <code class="highlighter-rouge">Target_EL</code>, <code class="highlighter-rouge">Target_ML</code>, etc.) tiers. Additionally, translate any non-English words on the <code class="highlighter-rouge">Translation</code> tier.</li> <li>The Target_Language tiers (English <code class="highlighter-rouge">Target_EL</code>, Mandarin <code class="highlighter-rouge">Target_CL</code>, Malay <code class="highlighter-rouge">Target_ML</code>) have assigned controlled vocabularies that contain all the picture cards words. The Tamil <code class="highlighter-rouge">Target_TL</code> tier requires manual input (i.e., typing) as the ELAN software does not allow for Tamil script in controlled vocabularies (yet).</li> </ul> </li> <li> <p>Ensure you mark out the start and end of the Picture Cards recording on the <code class="highlighter-rouge">ActivityMarkers</code> tier. <strong>Do this even if the recording only contains one word, or if the recording for the Picture Cards activity is contained within a larger recording that also includes the other Voicemail Game activities (Picture Prompts/Green Grass Park).</strong></p> <ul> <li><code class="highlighter-rouge">:marker:start:ads_voweltri_[language]</code> should be used to mark the start of the picture cards activity (e.g., <code class="highlighter-rouge">:marker:start:ads_voweltri_Tamil</code> would be used to demarcate the start of the Tamil picture cards recording).</li> <li><code class="highlighter-rouge">:marker:end:ads_voweltri_[language]</code> should be used to mark the end of the picture cards activity (e.g., <code class="highlighter-rouge">:marker:start:ads_voweltri_Tamil</code> would be used to demarcate the end of the Tamil picture cards recording).</li> <li>Watch our video <a href="https://youtu.be/pDTGJypkt8Y">here</a> or the read the <a href="/belacon/BELA/convention/tier-guide.html#activity-marker-tier">activity markers section</a> in our tier guide in this wiki should you need more guidance on how the ActivityMarkers tier works.</li> </ul> </li> </ol> <p>Back to <a href="#contents">table of contents</a></p><hr /> <h2 id="transcribing-voicemail-game-talk-prompts-recordings"> <a href="#transcribing-voicemail-game-talk-prompts-recordings" class="anchor-heading" aria-labelledby="transcribing-voicemail-game-talk-prompts-recordings"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Transcribing Voicemail Game Talk Prompts Recordings </h2> <p><strong><em>For a video demonstration of transcribing a talk prompts recording, please watch <a href="https://youtu.be/nhIgQ2q_YC0">this video</a> from our playlist.</em></strong></p> <p>As part of the Voicemail Game in this study, participants will record an audio recording of their responses to three different Voicemail Game activities in English and also in their other preferred language (Mandarin, Malay, or Tamil. The second activity of the Voicemail Game is the Talk Prompts activity.</p> <p>Participants are given a set of eight (8) topics in English and in their other preferred language. They select one topic in each language, and record their response to the chosen topic prompt in the respective languages. The recording should only contain one adult speaker.</p> <p>Visit <a href="https://blogs.ntu.edu.sg/blip/baby/talktogetherstudy/audio/talkprompts/">this page</a> to see all the topic prompts sorted by language.</p> <ol> <li> <p>Import the audio file (.wav) <em>and</em> the template file (.etf) into ELAN. Refer to the “Transcription Template” section of the wiki on instructions on how to handle the template subsequent to importing it.</p> </li> <li> <p>Go to “File” and click “Save” or “Save As” like a normal document. The file should be named according to the file naming conventions outlined on the wiki. You can also set an automatic backup of the file by going to “File” &gt; “Automatic Backup”. Choose a time interval between 1 to 30 minutes that suits your preference. Note: the backup file will be saved with the extension <code class="highlighter-rouge">*.eaf.001</code>.</p> </li> <li> <p>In order to see the hierarchical relationship between the dependent tiers, right click on the tier sidebar &gt; Sort Tiers &gt; Sort by Hierarchy.</p> </li> <li> <p>Listen to the audio file in full before you begin transcribing. Mentally note what languages are being spoken. Note any muffled parts or parts where all speech become indecipherable. Information on how to deal with these parts can be found under Frequently Asked Questions (FAQ).</p> </li> <li> <p>Edit the tier attributes to replace placeholder participant codes with accurate participant ID codes for all the participants present in the recording. This should be done on all the present participant’s primary and secondary tiers.(e.g. if the participant ID is <code class="highlighter-rouge">P1234TT</code> and the mother is the only speaker in this recording, the Mother code <code class="highlighter-rouge">MPXXXXTT</code> should be edited to <code class="highlighter-rouge">MP1234TT</code> on all the Mother primary and secondary tiers). <strong>DO NOT DELETE UNUSED TIERS. Right click on the tier panel and hide them if they are getting in your way</strong></p> </li> <li> <p>Adjust the vertical zoom (right click on the waveform &gt; Vertical Zoom &gt; adjust the %) and horizontal zoom (adjust the slider at the bottom right of the ELAN screen) to help you see the waveform clearly.</p> </li> <li> <p>Put on your headphones and begin transcribing the audio file. Utilise the <code class="highlighter-rouge">Utterance</code>, <code class="highlighter-rouge">Chunk</code>, and <code class="highlighter-rouge">Language</code> tier. For recordings of responses to prompts in the preferred languages (Mandarin, Malay, Tamil), utilise the <code class="highlighter-rouge">Translation</code> tier as well.</p> </li> <li> <p>Ensure you mark out the start and end of the Talk Prompts recording on the <code class="highlighter-rouge">ActivityMarkers</code> tier. <strong>Do this even if the recording for the Talk Prompts activity is contained within a larger recording that also includes the other activities (Picture Cards/Green Grass Park).</strong></p> <ul> <li><code class="highlighter-rouge">:marker:start:ads_prompts_[language]</code> should be used to mark the start of the talk prompts activity (e.g., <code class="highlighter-rouge">:marker:start:ads_prompts_Eng</code> would be used to demarcate the start of the English talk prompts recording).</li> <li><code class="highlighter-rouge">:marker:end:ads_prompts_[language]</code> should be used to mark the end of the talk prompts activity (e.g., <code class="highlighter-rouge">:marker:start:ads_voweltri_Eng</code> would be used to demarcate the end of the Eng talk prompts recording).</li> <li>Watch our video <a href="https://youtu.be/pDTGJypkt8Y">here</a> or the read the <a href="/belacon/BELA/convention/tier-guide.html#activity-marker-tier">activity markers section</a> in our tier guide in this wiki should you need more guidance on how the ActivityMarkers tier works.</li> </ul> </li> </ol> <p>Back to <a href="#contents">table of contents</a></p><hr /> <h2 id="transcribing-voicemail-game-green-grass-park-recordings"> <a href="#transcribing-voicemail-game-green-grass-park-recordings" class="anchor-heading" aria-labelledby="transcribing-voicemail-game-green-grass-park-recordings"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Transcribing Voicemail Game Green Grass Park Recordings </h2> <p><strong><em>For a video demonstration of transcribing a green grass park recording from the voicemail game, please watch <a href="https://youtu.be/1vtuOQ4pCIM">this video</a> from our playlist.</em></strong></p> <p>As part of the Voicemail Game in this study, participants will record an audio recording of their responses to three different Voicemail Game activities in English and also in their other preferred language (Mandarin, Malay, or Tamil. The third and last activity of the Voicemail Game is the Green Grass Park activity.</p> <p>Participants are given a picture prompt called “Green Grass Park”. There are three version of the picture; a Mandarin version, a Malay version, and a Tamil Version. All three versions also have English on them. The Mandarin/Malay/Tamil words on the image are “target” words. Participants select one version and record themselves describing what they see in the picture. They are given the option to use whichever presented language they are most comfortable with, or to mix them. The recording should only contain one adult speaker.</p> <p>Visit <a href="https://blogs.ntu.edu.sg/blip/baby/talktogetherstudy/audio/greengrasspark/">this page</a> to see all the Green Grass Park pictures sorted by language (click the images on the page to enlarge them).</p> <ol> <li> <p>Have the Green Grass Park image open. This is so you can reference it to identify the participant’s use of any Mandarin/Malay/Tamil target words in their recording.</p> </li> <li> <p>Import the audio file (.wav) <em>and</em> the template file (.etf) into ELAN. Refer to the “Transcription Template” section of the wiki on instructions on how to handle the template subsequent to importing it.</p> </li> <li> <p>In order to see the hierarchical relationship between the dependent tiers, right click on the tier sidebar &gt; Sort Tiers &gt; Sort by Hierarchy.</p> </li> <li> <p>Go to “File” and click “Save” or “Save As” like a normal document. The file should be named according to the file naming conventions outlined on the wiki. You can also set an automatic backup of the file by going to “File” &gt; “Automatic Backup”. Choose a time interval between 1 to 30 minutes that suits your preference. Note: the backup file will be saved with the extension <code class="highlighter-rouge">*.eaf.001</code>.</p> </li> <li> <p>Listen to the audio file in full before you begin transcribing. Mentally note what languages are being spoken. Note any muffled parts or parts where all speech become indecipherable. Information on how to deal with these parts can be found under Frequently Asked Questions (FAQ).</p> </li> <li> <p>Edit the tier attributes to replace placeholder participant codes with accurate participant ID codes for all the participants present in the recording. This should be done on all the present participant’s primary and secondary tiers.(e.g. if the participant ID is <code class="highlighter-rouge">P1234TT</code> and the mother is the only speaker in this recording, the Mother code <code class="highlighter-rouge">MPXXXXTT</code> should be edited to <code class="highlighter-rouge">MP1234TT</code> on all the Mother primary and secondary tiers). <strong>DO NOT DELETE UNUSED TIERS. Right click on the tier panel and hide them if they are getting in your way</strong></p> </li> <li> <p>Adjust the vertical zoom (right click on the waveform &gt; Vertical Zoom &gt; adjust the %) and horizontal zoom (adjust the slider at the bottom right of the ELAN screen) to help you see the waveform clearly.</p> </li> <li>Put on your headphones and begin transcribing the audio file. <ul> <li>Transcribe utterances on the <code class="highlighter-rouge">Utterance</code>, <code class="highlighter-rouge">Chunk</code>, and <code class="highlighter-rouge">Language</code> tiers. Also use the <code class="highlighter-rouge">Translation</code> tier should you need to translate non-English utterances into English.</li> <li>Isolate and transcribe any instances of individual target words on the relevant <code class="highlighter-rouge">Target_Language</code> (i.e., <code class="highlighter-rouge">Target_CL</code>, <code class="highlighter-rouge">Target_ML</code>, or <code class="highlighter-rouge">Target_TL</code>) tiers.</li> <li>The Target_Language tiers (Mandarin <code class="highlighter-rouge">Target_CL</code>, Malay <code class="highlighter-rouge">Target_ML</code>) have assigned controlled vocabularies that contain all the Green Grass Park Mandarin/Malay Green Grass Park target words. The Tamil <code class="highlighter-rouge">Target_TL</code> tier requires manual input (i.e., typing) as the ELAN software does not allow for Tamil script in controlled vocabularies (yet).</li> </ul> </li> <li> <p>Ensure you mark out the start and end of the Green Grass Park recording on the <code class="highlighter-rouge">ActivityMarkers</code> tier. <strong>Do this even if the recording for the Green Grass Park activity is contained within a larger recording that also includes the other activities (Picture Cards/Talk Prompts).</strong></p> <ul> <li><code class="highlighter-rouge">:marker:start:ads_ggp</code> should be used to mark the start of the Voicemail Game Green Grass Park activity.</li> <li><code class="highlighter-rouge">:marker:end:ads_ggp</code> should be used to mark the end of the Voicemail Game Green Grass Park activity</li> <li>Watch our video <a href="https://youtu.be/pDTGJypkt8Y">here</a> or the read the <a href="/belacon/BELA/convention/tier-guide.html#activity-marker-tier">activity markers section</a> in our tier guide in this wiki should you need more guidance on how the ActivityMarkers tier works.</li> </ul> </li> </ol> <p>Back to <a href="#contents">table of contents</a></p><hr /> <h2 id="transcribing-video-call-storytime-phase-1-recordings"> <a href="#transcribing-video-call-storytime-phase-1-recordings" class="anchor-heading" aria-labelledby="transcribing-video-call-storytime-phase-1-recordings"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Transcribing Video Call Storytime Phase 1 Recordings </h2> <p>The Video Call Storytime (VCST) activity in the Talk Together Study is a recording of an interaction between a parent and child over a video call (Zoom). The Phase/Timepoint 1 VCST recording includes:</p> <ul> <li>The parent reading “The Little Orangutan: What a Scary Storm” book to their child. The researcher shares this book on screen.</li> </ul> <p>The VCST will usually include one Parent (Father or Mother), one Baby, and one Researcher. There may be instances where another person’s voice may appear in the recording (e.g., a sibling of the baby, another family member, etc.)</p> <ol> <li>Watch the VIDEO recording file in full before you begin transcribing. <ul> <li>Familiarize yourself with the participants’ voices and any contextual information.</li> <li>Note how many participants there are. Identify the participant by their relationship to the baby.</li> <li>Note what languages are being spoken.</li> <li>Note down the timepoints when the story reading segment starts and ends for ActivityMarker purposes <ul> <li>the start of the story segment is the very start of the recording, including researcher instruction/speech</li> <li>the end of the story segment is usually when the parent/child says <em>‘the end’</em> or finishes recapping the story or finishes talking about the orangutan holding pencils on the last page of the book. The ending marker should be placed right before the researcher comes back into the recording and says something along the lines of <em>“Thank you! You and your child looked like you were having so much fun….”</em> If you’re unsure, ask a full-time staff member.</li> </ul> </li> <li>Note any muffled parts or parts where all speech become indecipherable. Information on how to deal with these parts can be found under Frequently Asked Questions (FAQ).</li> </ul> </li> <li> <p>Import the associated AUDIO (.wav) file <em>and</em> the template file (.etf) into ELAN. Refer to the “Transcription Template” section of the wiki on instructions on how to handle the template subsequent to importing it.</p> </li> <li> <p>a) Go to “File” and click “Save” or “Save As” like a normal document. The file should be named according to the file naming conventions outlined on the wiki. You can also set an automatic backup of the file by going to “File” &gt; “Automatic Backup”. Choose a time interval between 1 to 30 minutes that suits your preference. Note: the backup file will be saved with the extension <code class="highlighter-rouge">*.eaf.001</code>.</p> <p>b) Update the transcription log - namely AudioFileName (Column B), TranscribedFileName (Column C), Project (Column D, in this case would be TTS), Audio Length (Column E), Language(s) spoken in the recording (Column G), Transcriber 1 (Column H, which would be your name), Date issued (Column I). It will also help to write down anything of note (e.g., audio dropping at any point, the length of an activity) into the Comments by Transcriber (Column M).</p> </li> <li> <p>Return to ELAN. In order to see the hierarchical relationship between the dependent tiers in ELAN, right click on the tier sidebar &gt; Sort Tiers &gt; Sort by Hierarchy.</p> </li> <li> <p>Edit the tier attributes to replace placeholder participant codes with accurate participant ID codes for all the participants present in the recording. This should be done on all the present participant’s primary and secondary tiers.(e.g. the participant ID is <code class="highlighter-rouge">P1234TT</code> and the mother, baby, and researcher (<code class="highlighter-rouge">R099</code>) are present in this recording. The Mother code <code class="highlighter-rouge">MPXXXXTT</code> should be edited to <code class="highlighter-rouge">MP1234TT</code> on all the Mother primary and secondary tiers. The Baby code <code class="highlighter-rouge">PXXXXTT</code> should be edited to <code class="highlighter-rouge">P1234TT</code> on all the Baby primary and secondary tiers. The Researcher code <code class="highlighter-rouge">R00XPxxxxTT</code> should be edited to <code class="highlighter-rouge">R099P1234TT</code> on all the Researcher primary and secondary tiers). <strong>DO NOT DELETE UNUSED TIERS. Right click on the tier panel and hide them if they are getting in your way</strong></p> </li> <li> <p>Adjust the vertical zoom (right click on the waveform &gt; Vertical Zoom &gt; adjust the %) and horizontal zoom (adjust the slider at the bottom right of the ELAN screen) to help you see the waveform clearly.</p> </li> <li>Put on your headphones and begin transcribing the <strong>story reading segment</strong> of the audio file. <ul> <li>Transcribe utterances on the <code class="highlighter-rouge">Utterance</code>, <code class="highlighter-rouge">Chunk</code>, and <code class="highlighter-rouge">Language</code> tiers. Use the <code class="highlighter-rouge">Translation</code> tier should you need to translate any non-English utterances into English.</li> <li>Isolate instances (e.g., mention of the baby’s name) that need redacting on the <a href="/belaconBELA/convention/tier-guide.html#sensitive_masking-tier"><code class="highlighter-rouge">Sensitive_Masking</code></a> tier. Live demo on how to use the Sensitive_Masking tier <a href="https://youtu.be/4KScOFyTgK4">here</a>.</li> <li>What counts as an utterance? Read “A Problem Named Utterance” by Dr. Shamala Sundaray, which can be found <a href="/belacon/assets/projects/TTS/docs/A problem named Utterance_20200730_20220225.pdf">here</a></li> <li>Utterances directed to the child and researcher should be separate. For instance, the parent may follow up an utterance to the child with a directive to the researcher, e.g., <strong>look at the monkey okay next page what is this</strong>. A part of the utterance is instructions directed to the researcher to flip the page during the storybook sharing task. Hence, it should be transcribed as separate utterances: <strong>look at the monkey, okay next page, what is this.</strong> In general, utterances directed to two different people should be considered as separate utterances. In some cases, prosodic information in the audio file may offer additional information on how to segment the utterance.</li> </ul> </li> <li>Decide how to transcribe speech <strong>unrelated</strong> to storybook reading. <ul> <li>There is a difference in transcription protocols and conventions when transcribing utterances related or unrelated to the storybook reading.</li> <li>As a general rule of thumb, we wish to transcribe speech that is observed during the story reading segment to understand how parents engage their children in a shared storybook reading exercise. During the story reading segment, there may be speech that is not related to the storybook reading. Examples: <ul> <li>questions or instructions to researchers (e.g., is the page supposed to turn?, next page),</li> <li>requests to pause the task (e.g., sorry can we pause?),</li> <li>talks to another person (e.g., Mother turning around to talk to Father that came into the room)</li> </ul> </li> <li>For the above scenarios, if the parent remains on screen and does not start a completely new task, speech should be transcribed as per normal.</li> <li>On the other hand, if the parent leaves the screen or starts a completely new task unrelated to story reading, we will partially transcribe the speech as outlined in Step 9 below.</li> <li>In order to decide which conventions should be used, this decision table should be used. If you are still unsure, please check in with any team members for further clarification.</li> </ul> <p><img src="/belacon/assets/projects/images/untranscribed_speech_flowchart.png" alt="untranscribed_speech_flowchart.png" /></p> </li> <li>Partially transcribe speech unrelated to storybook reading. <ul> <li>For the portions before the start and after the end of story reading segment of the audio file, if any speaker is talking, mark the onsets and offsets of each utterance.</li> <li>As we only wish to transcribe speech during story reading segment, utterances that occur before the start of story reading and utterances that occur after the end of story reading should be labelled but do not need to be fully transcribed.</li> <li>If the utterance only contains speech and vocal sounds, demarcate the onset and offset of the utterance. Type <code class="highlighter-rouge">*untranscribed_speech*</code> (with the asterisks) in the Utterance and Chunk tiers. Then, use the Vocal Sounds tag in the Language tier. There is no need to demarcate the onsets and offsets of different languages or vocal sounds for each utterance. If the Baby makes noises/speaks, follow the same procedure in the Utterance and Chunk tiers, and the Language tag is Vocal Sounds as well. This is the only time Vocal Sounds can be used in the Baby (Language) tier.</li> </ul> <p><img src="/belacon/assets/projects/TAT/images/untranscribed_speech_elan_babyname.png" alt="untranscribed_speech_elan_babyname.png" /></p> <ul> <li>If the utterance only contains non-vocal sounds, it should be labelled with the appropriate tags. Example, if there is clapping, <code class="highlighter-rouge">:s:clapping</code> should be enclosed in the Utterance and Chunk tiers, while Non Vocal Sounds should be used in the Language tier. Note that the chime sound that plays when the orangutan storybook pages turn should not be transcribed. Mouse clicks should not be transcribed either. Read our section on non-vocal sounds <a href="/belacon/BELA/convention/special-characters.html#2-non-vocal-sounds">here</a> should you need additional guidance on what non-vocal sounds should be labelled.</li> </ul> <p><img src="/belacon/assets/projects/TAT/images/untranscribed_speech_elan_clapping.png" alt="untranscribed_speech_elan_clapping.png" /></p> <ul> <li>If the utterance contains both non-vocal sounds and speech, the onset and offset of speech and non vocal sounds should be demarcated accordingly. If the chime sound that plays when the orangutan storybook pages turn or mouse clicking sounds happen in between untranscribed speech, there is no need to demarcate them.</li> <li>If you hear names or items to be redacted, isolate these instances the in SENSITIVE_MASKING tiers. Refer to <a href="/belacon/BELA/convention/privacy.html#privacy-matters">this site</a> to see what should be redacted. <ul> <li>If more than one Sensitive_Masking tag appears in an utterance, they should be added by order of which they appear. For example, if the Mother says the sibling’s name followed by some words and then the baby’s name, you should transcribe it as: <code class="highlighter-rouge">*untranscribed_speech* SIBLINGNAME BABYNAME</code> in the Utterance and Chunk tier. Then isolate the instances of each name in the SENSITIVE_MASKING tier of the Mother.</li> </ul> </li> </ul> <p><img src="/belacon/assets/projects/TAT/images/untranscribed_speech_elan_siblingname.png" alt="untranscribed_speech_elan_siblingname.png" /></p> <ul> <li><strong>IMPORTANT:</strong> If you are unsure whether to redact an audio region, please consult the team for a second opinion. It’s important for us to ascertain carefully if an audio region should be redacted or not to protect the privacy of our participants.</li> </ul> <p><strong>NOTE:</strong> We recommend future researchers to do Steps 8 and 9 while transcribing the audio file. These steps were done post-hoc when transcribing the Talk Together Study audio files and added into the transcription protocol after. Since July 2023, these steps have been fully integrated into the BLIP lab’s transcription workflow (see Talk-a-thon VCST protocol).</p> </li> <li> <p>Ensure you mark out the start and end of the story reading segment in the recording on the <code class="highlighter-rouge">ActivityMarkers</code> tier. Follow the guidelines in step 1 to get an understanding of where each activity starts and ends. Do consult a full-time staff member should you have any questions.</p> <ul> <li><code class="highlighter-rouge">:marker:start:cds_book</code> should be used to mark the start of the Story Reading segment.</li> <li><code class="highlighter-rouge">:marker:end:cds_book</code> should be used to mark the end of the Story Reading Segment.</li> <li>Watch our video <a href="https://youtu.be/pDTGJypkt8Y">here</a> or the read the <a href="/belacon/BELA/convention/tier-guide.html#activity-marker-tier">activity markers section</a> in our tier guide in this wiki should you need more guidance on how the ActivityMarkers tier works.</li> </ul> </li> <li> <p>Update the transcription log to note your transcription progress on a given file.</p> <p>a) If you’re still working on the file, note “ongoing” in Column J (actual trans. hrs) and add the date and amount of audio transcribed in the 1st or 2nd listen column (Column K and L, respectively).</p> <p>b) If you have finished transcribing a file alert a full-time staff member, update Column J (actual trans. hrs) with the number of hours it took you to complete the transcription, and write the dates of completion of each listen in Column K and L.</p> <p>For more information about each column in the Transcription Log, please refer to <a href="/belacon/Projects/TTS/transcription-log.html">this page</a> in the wiki.</p> </li> </ol> <p>Back to <a href="#contents">table of contents</a></p><hr /> <h2 id="transcribing-video-call-storytime-phase-2-recordings"> <a href="#transcribing-video-call-storytime-phase-2-recordings" class="anchor-heading" aria-labelledby="transcribing-video-call-storytime-phase-2-recordings"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Transcribing Video Call Storytime Phase 2 Recordings </h2> <p>The Video Call Storytime (VCST) activity in the Talk Together Study is a recording of an interaction between a parent and child over a video call (Zoom). The Phase/Timepoint 2 VCST recordings includes:</p> <ul> <li>The parent describing the “Green Grass Park” picture prompt to their child. The parent has a maximum of 5 minutes but can choose to end this activity earlier. <strong>The Green Grass Park pictures for the VCST are different from the Voicemail game version, and the transcriber does not need to isolate and transcribe any target words.</strong></li> <li>The parent reading “The Little Orangutan: What a Scary Storm” book to their child</li> </ul> <p>The VCST will usually include one Parent (Father or Mother), one Baby, and one Researcher. There may be instances where another person’s voice may appear in the recording (e.g., a sibling of the baby, another family member, etc.)</p> <ol> <li>Watch the VIDEO recording file in full before you begin transcribing. <ul> <li>Familiarize yourself with the participants’ voices and any contextual information.</li> <li>Note how many participants there are. Identify the participant by their relationship to the baby.</li> <li>Note what languages are being spoken.</li> <li>Note down the timepoints when the Green Grass Park (GGP) segment starts and ends for ActivityMarker purposes <ul> <li>The start of the GGP segment is the very start of the recording, including researcher instruction/speech</li> <li>The end of the GGP segment is usually when the researcher says something along the lines of <em>“Time’s up! That was great”</em> (meaning the parent reacher the 5 minutes), or if the parent says something along the lines of <em>“Next. I’m ready to move on to the next activity”</em>.</li> </ul> </li> <li>Note down the timepoints when the story reading segment starts and ends for ActivityMarker purposes <ul> <li>The start of the story segment is when the researcher says something along the lines of <em>“I will now switch off my camera. Just remember, once you are ready to go to the next page, you can tell me ‘Next!’ Are you ready? Okay let’s begin”</em>. Ensure you include this researcher instruction/speech within the starting marker.</li> <li>The end of the story segment is usually when the parent/child says <em>‘the end’</em> or finish recapping the story or finish talking about the orangutan holding pencils on the last page of the book. The ending marker should be placed right before the researcher comes back into the recording and says something along the lines of <em>“Thank you! You and your child looked like you were having so much fun….”</em> If you’re unsure, ask a full-time staff member.</li> </ul> </li> <li>Note any muffled parts or parts where all speech become indecipherable. Information on how to deal with these parts can be found under Frequently Asked Questions (FAQ).</li> </ul> </li> <li> <p>Import the associated AUDIO (.wav) file <em>and</em> the template file (.etf) into ELAN. Refer to the “Transcription Template” section of the wiki on instructions on how to handle the template subsequent to importing it.</p> </li> <li> <p>a) Go to “File” and click “Save” or “Save As” like a normal document. The file should be named according to the file naming conventions outlined on the wiki. You can also set an automatic backup of the file by going to “File” &gt; “Automatic Backup”. Choose a time interval between 1 to 30 minutes that suits your preference. Note: the backup file will be saved with the extension <code class="highlighter-rouge">*.eaf.001</code>.</p> <p>b) Update the transcription log - namely AudioFileName (Column B), TranscribedFileName (Column C), Project (Column D, in this case would be TTS), Audio Length (Column E), Language(s) spoken in the recording (Column G), Transcriber 1 (Column H, which would be your name), Date issued (Column I). It will also help to write down anything of note (e.g., audio dropping at any point, the length of an activity) into the Comments by Transcriber (Column M).</p> </li> <li> <p>Return to ELAN. In order to see the hierarchical relationship between the dependent tiers, right click on the tier sidebar &gt; Sort Tiers &gt; Sort by Hierarchy.</p> </li> <li> <p>Edit the tier attributes to replace placeholder participant codes with accurate participant ID codes for all the participants present in the recording. This should be done on all the present participant’s primary and secondary tiers.(e.g. the participant ID is <code class="highlighter-rouge">P1234TT</code> and the mother, baby, and researcher (<code class="highlighter-rouge">R099</code>) are present in this recording. The Mother code <code class="highlighter-rouge">MPXXXXTT</code> should be edited to <code class="highlighter-rouge">MP1234TT</code> on all the Mother primary and secondary tiers. The Baby code <code class="highlighter-rouge">PXXXXTT</code> should be edited to <code class="highlighter-rouge">P1234TT</code> on all the Baby primary and secondary tiers. The Researcher code <code class="highlighter-rouge">R00XPxxxxTT</code> should be edited to <code class="highlighter-rouge">R099P1234TT</code> on all the Researcher primary and secondary tiers). <strong>DO NOT DELETE UNUSED TIERS. Right click on the tier panel and hide them if they are getting in your way</strong></p> </li> <li> <p>Adjust the vertical zoom (right click on the waveform &gt; Vertical Zoom &gt; adjust the %) and horizontal zoom (adjust the slider at the bottom right of the ELAN screen) to help you see the waveform clearly.</p> </li> <li>Put on your headphones and begin transcribing the <strong>story reading segment</strong> and <strong>GGP segment</strong> of the audio file. <ul> <li>Transcribe utterances on the <code class="highlighter-rouge">Utterance</code>, <code class="highlighter-rouge">Chunk</code>, and <code class="highlighter-rouge">Language</code> tiers. Use the <code class="highlighter-rouge">Translation</code> tier if you need to translate any non-English utterances into English.</li> <li>Isolate instances (e.g., mention of the baby’s name) that need redacting on the <a href="/belaconBELA/convention/tier-guide.html#sensitive_masking-tier"><code class="highlighter-rouge">Sensitive_Masking</code></a> tier. Live demo on how to use the Sensitive_Masking tier <a href="https://youtu.be/4KScOFyTgK4">here</a>.</li> <li>What counts as an utterance? Read “A Problem Named Utterance” by Dr. Shamala Sundaray, which can be found <a href="/belacon/assets/projects/TTS/docs/A problem named Utterance_20200730_20220225.pdf">here</a></li> <li>Utterances directed to the child and researcher should be separate. For instance, the parent may follow up an utterance to the child with a directive to the researcher, e.g., <strong>look at the monkey okay next page what is this</strong>. A part of the utterance is instructions directed to the researcher to flip the page during the storybook sharing task. Hence, it should be transcribed as separate utterances: <strong>look at the monkey, okay next page, what is this.</strong> In general, utterances directed to two different people should be considered as separate utterances. In some cases, prosodic information in the audio file may offer additional information on how to segment the utterance.</li> </ul> </li> <li>Decide how to transcribe speech unrelated to storybook reading and unrelated to GGP segments. <ul> <li>There is a difference in transcription protocols and conventions when transcribing utterances related or unrelated to the activities in the audio recording (in this case, storybook reading and GGP).</li> <li>As a general rule of thumb, we wish to transcribe speech that is observed during the story reading and GGP segments to understand how parents engage their children in these shared activities. During these activities, there may be speech that is not related to the activities. Examples: <ul> <li>questions or instructions to researchers (e.g., is the page supposed to turn?, next page),</li> <li>requests to pause the task (e.g., sorry can we pause?),</li> <li>talks to another person (e.g., Mother turning around to talk to Father that came into the room)</li> </ul> </li> <li>For the above scenarios, if the parent remains on screen and does not start a completely new task, speech should be transcribed as per normal.</li> <li>On the other hand, if the parent leaves the screen or starts a completely new task unrelated to story reading or GGP, we will partially transcribe the speech as outlined in Step 9 below.</li> <li>In order to decide which conventions should be used, this decision table should be used. If you are still unsure, please check in with any team members for further clarification.</li> </ul> <p><img src="/belacon/assets/projects/images/untranscribed_speech_flowchart.png" alt="untranscribed_speech_flowchart.png" /></p> </li> <li>Partially transcribe speech unrelated to storybook reading or GGP segements. <ul> <li>For the portions before the start and after the end of story reading and GGP segments of the audio file, if any speaker is talking, mark the onsets and offsets of each utterance.</li> <li>As we only wish to transcribe speech during story reading or GGP segments, utterances that occur before the start of story reading (and GGP) and utterances that occur after the end of story reading (and GGP) should be labelled but do not need to be fully transcribed.</li> <li>Utterances that occur during the transition of GGP to storybook reading should also be labelled and do not need to be fully transcribed.</li> <li>If the utterance only contains speech and vocal sounds, demarcate the onset and offset of the utterance. Type <code class="highlighter-rouge">*untranscribed_speech*</code> (with the asterisks) in the Utterance and Chunk tiers. Then, use the Vocal Sounds tag in the Language tier. There is no need to demarcate the onsets and offsets of different languages or vocal sounds for each utterance. If the Baby makes noises/speaks, follow the same procedure in the Utterance and Chunk tiers, and the Language tag is Vocal Sounds as well. This is the only time Vocal Sounds can be used in the Baby (Language) tier.</li> </ul> <p><img src="/belacon/assets/projects/TAT/images/untranscribed_speech_elan_babyname.png" alt="untranscribed_speech_elan_babyname.png" /></p> <ul> <li>If the utterance only contains non-vocal sounds, it should be labelled with the appropriate tags. Example, if there is clapping, <code class="highlighter-rouge">:s:clapping</code> should be enclosed in the Utterance and Chunk tiers, while Non Vocal Sounds should be used in the Language tier. Note that the chime sound that plays when the orangutan storybook pages turn should not be transcribed. Mouse clicks should not be transcribed either. Read our section on non-vocal sounds <a href="/belacon/BELA/convention/special-characters.html#2-non-vocal-sounds">here</a> should you need additional guidance on what non-vocal sounds should be labelled.</li> </ul> <p><img src="/belacon/assets/projects/TAT/images/untranscribed_speech_elan_clapping.png" alt="untranscribed_speech_elan_clapping.png" /></p> <ul> <li>If the utterance contains both non-vocal sounds and speech, the onset and offset of speech and non vocal sounds should be demarcated accordingly. If the chime sound that plays when the orangutan storybook pages turn or mouse clicking sounds happen in between untranscribed speech, there is no need to demarcate them.</li> <li>If you hear names or items to be redacted, isolate these instances the in SENSITIVE_MASKING tiers. Refer to <a href="/belacon/BELA/convention/privacy.html#privacy-matters">this site</a> to see what should be redacted. <ul> <li>If more than one Sensitive_masking tag appears in an utterance, they should be added by order of which they appear. For example, if the Mother says the sibling’s name followed by some words and then the baby’s name, you should transcribe it as: <code class="highlighter-rouge">*untranscribed_speech* SIBLINGNAME BABYNAME</code> in the Utterance and Chunk tier. Then isolate the instances of each name in the SENSITIVE_MASKING tier of the Mother.</li> </ul> <p><img src="/belacon/assets/projects/TAT/images/untranscribed_speech_elan_siblingname.png" alt="untranscribed_speech_elan_siblingname.png" /></p> </li> <li><strong>IMPORTANT:</strong> If you are unsure whether to redact an audio region, please consult the team for a second opinion. It’s important for us to ascertain carefully if an audio region should be redacted or not to protect the privacy of our participants.</li> </ul> <p><strong>NOTE:</strong> We recommend future researchers to do Steps 8 and 9 while transcribing the audio file. These steps were done post-hoc when transcribing the Talk Together Study audio files and added into the protocol after. Since July 2023, these steps have been fully integrated into the BLIP lab’s transcription workflow (see Talkathon VCST protocol).</p> </li> <li> <p>Ensure you mark out the start and end of the GGP segment and story reading segment in the recording on the <code class="highlighter-rouge">ActivityMarkers</code> tier. Follow the guidelines in step 1 to get an understanding of where each activity starts and ends. Do consult a full-time staff member should you have any questions.</p> <ul> <li><code class="highlighter-rouge">:marker:start:cds_ggp</code> should be used to mark the start of the VCST Green Grass Park segment.</li> <li><code class="highlighter-rouge">:marker:end:cds_ggp</code> should be used to mark the end of the VCST Green Grass Park segment.</li> <li><code class="highlighter-rouge">:marker:start:cds_book</code> should be used to mark the start of the Story Reading segment.</li> <li><code class="highlighter-rouge">:marker:end:cds_book</code> should be used to mark the end of the Story Reading Segment.</li> <li>Watch our video <a href="https://youtu.be/pDTGJypkt8Y">here</a> or the read the <a href="/belacon/BELA/convention/tier-guide.html#activity-marker-tier">activity markers section</a> in our tier guide in this wiki should you need more guidance on how the ActivityMarkers tier works.</li> </ul> </li> <li> <p>Update the transcription log to note your transcription progress on a given file.</p> <p>a) If you’re still working on the file, note “ongoing” in Column J (actual trans. hrs) and add the date and amount of audio transcribed in the 1st or 2nd listen column (Column K and L, respectively).</p> <p>b) If you have finished transcribing a file alert a full-time staff member, update Column J (actual trans. hrs) with the number of hours it took you to complete the transcription, and write the dates of completion of each listen in Column K and L.</p> <p>For more information about each column in the Transcription Log, please refer to <a href="/belacon/Projects/TTS/transcription-log.html">this page</a> in the wiki.</p> </li> </ol> <p>Back to <a href="#contents">table of contents</a></p><hr /> <h2 id="transcribing-video-call-storytime-phase-3-recordings"> <a href="#transcribing-video-call-storytime-phase-3-recordings" class="anchor-heading" aria-labelledby="transcribing-video-call-storytime-phase-3-recordings"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Transcribing Video Call Storytime Phase 3 Recordings </h2> <p>The Video Call Storytime (VCST) activity in the Talk Together Study is a recording of an interaction between a parent and child over a video call (Zoom). The Phase/Timepoint 3 VCST recordings includes:</p> <ul> <li>The parent reading the <a href="https://blogs.ntu.edu.sg/blip/baby/talktogetherstudy/audio/picturecards/">picture cards/vowel triangle cards</a> to their child in English and their preferred language (Mandarin, Malay, or Tamil). <strong>As per protocol change on 15th November 2021, the Picture Cards activity will now be fully transcribed. See point 7(a) below for more details.</strong></li> <li>The parent reading “The Little Orangutan: What a Scary Storm” book to their child</li> </ul> <p>The VCST will usually include one Parent (Father or Mother), one Baby, and one Researcher. There may be instances where another person’s voice may appear in the recording (e.g., a sibling of the baby, another family member, etc.)</p> <ol> <li>Watch the VIDEO recording file in full before you begin transcribing. <ul> <li>Familiarize yourself with the participants’ voices and any contextual information.</li> <li>Note how many participants there are. Identify the participant by their relationship to the baby.</li> <li>Note what languages are being spoken.</li> <li>Note down the timepoints when the Picture Cards (PC) segment starts and ends for ActivityMarker purposes <ul> <li>The start of the PC segment is the very start of the recording, including researcher instruction/speech</li> <li>The end of the PC segment is usually when the researcher says something along the lines of <em>“That was great! Thank you so much”</em> (indicating that the parents has read through all the necessary cards), or if the parent says something along the lines of <em>“Next. I’m ready to move on to the next activity”</em>.</li> </ul> </li> <li>Note down the timepoints when the story reading segment starts and ends for ActivityMarker purposes <ul> <li>The start of the story segment is when the researcher says something along the lines of <em>“I will now switch off my camera. Just remember, once you are ready to go to the next page, you can tell me ‘Next!’ Are you ready? Okay let’s begin”</em>. Ensure you include this researcher instruction/speech within the starting marker.</li> <li>The end of the story segment is usually when the parent/child says <em>‘the end’</em> or finish recapping the story or finish talking about the orangutan holding pencils on the last page of the book. The ending marker should be placed right before the researcher comes back into the recording and says something along the lines of <em>“Thank you! You and your child looked like you were having so much fun….”</em> If you’re unsure, ask a full-time staff member.</li> </ul> </li> <li>Note any muffled parts or parts where all speech become indecipherable. Information on how to deal with these parts can be found under Frequently Asked Questions (FAQ).</li> </ul> </li> <li> <p>Import the associated AUDIO (.wav) file <em>and</em> the template file (.etf) into ELAN. Refer to the “Transcription Template” section of the wiki on instructions on how to handle the template subsequent to importing it.</p> </li> <li> <p>a) Go to “File” and click “Save” or “Save As” like a normal document. The file should be named according to the file naming conventions outlined on the wiki. You can also set an automatic backup of the file by going to “File” &gt; “Automatic Backup”. Choose a time interval between 1 to 30 minutes that suits your preference. Note: the backup file will be saved with the extension <code class="highlighter-rouge">*.eaf.001</code>.</p> <p>b) Update the transcription log - namely AudioFileName (Column B), TranscribedFileName (Column C), Project (Column D, in this case would be TTS), Audio Length (Column E), Language(s) spoken in the recording (Column G), Transcriber 1 (Column H, which would be your name), Date issued (Column I). It will also help to write down anything of note (e.g., audio dropping at any point, the length of an activity) into the Comments by Transcriber (Column M).</p> </li> <li> <p>In order to see the hierarchical relationship between the dependent tiers, right click on the tier sidebar &gt; Sort Tiers &gt; Sort by Hierarchy.</p> </li> <li> <p>Edit the tier attributes to replace placeholder participant codes with accurate participant ID codes for all the participants present in the recording. This should be done on all the present participant’s primary and secondary tiers.(e.g. the participant ID is <code class="highlighter-rouge">P1234TT</code> and the mother, baby, and researcher (<code class="highlighter-rouge">R099</code>) are present in this recording. The Mother code <code class="highlighter-rouge">MPXXXXTT</code> should be edited to <code class="highlighter-rouge">MP1234TT</code> on all the Mother primary and secondary tiers. The Baby code <code class="highlighter-rouge">PXXXXTT</code> should be edited to <code class="highlighter-rouge">P1234TT</code> on all the Baby primary and secondary tiers. The Researcher code <code class="highlighter-rouge">R00XPxxxxTT</code> should be edited to <code class="highlighter-rouge">R099P1234TT</code> on all the Researcher primary and secondary tiers). <strong>DO NOT DELETE UNUSED TIERS. Right click on the tier panel and hide them if they are getting in your way</strong></p> </li> <li> <p>Adjust the vertical zoom (right click on the waveform &gt; Vertical Zoom &gt; adjust the %) and horizontal zoom (adjust the slider at the bottom right of the ELAN screen) to help you see the waveform clearly.</p> </li> <li> <p>Put on your headphones and begin transcribing the <strong>PC segment</strong> (a) and <strong>story reading segment</strong> (b) of the audio file.</p> <blockquote> <p>7a. <em>Transcribing the PC segment</em> <img src="/belacon/assets/projects/images/t3_picturecards_eng_20211126.png" alt="t3_picturecards_eng_20211126.png" /></p> </blockquote> <p><img src="/belacon/assets/projects/images/t3_picturecards_mandarin_20211126.png" alt="t3_picturecards_mandarin_20211126.png" /></p> <blockquote> <ul> <li>For the picture cards segment during the timepoint 3 video call story time, transcribers need to also can isolate the <a href="https://blogs.ntu.edu.sg/blip/baby/talktogetherstudy/audio/picturecards/">target words</a> spoken by the parent or child on the participants’ respective <code class="highlighter-rouge">Target</code> word tiers (e.g., <code class="highlighter-rouge">Target_EL</code> for target English words). Please see the two images above as examples.</li> <li>Target word tiers for the baby do not have a controlled vocabulary assigned to them. Transcribers can freely transcribe any instance of the baby’s attempt at vocalising a target word (e.g., if a baby says ‘pa’ instead of ‘pea’).</li> <li>The picture card activity is looking to elicit the following sounds: <blockquote> <ul> <li><strong>xi</strong> (for Mandarin Picture Cards)</li> <li><strong>si</strong> (for Mandarin Picture Cards)</li> <li><strong>pi</strong> (for English, Mandarin, Tamil, Malay Picture Cards)</li> <li><strong>pa</strong> (for English, Mandarin, Tamil, Malay Picture Cards)</li> <li><strong>pu</strong> (for English, Mandarin, Tamil, Malay Picture Cards)</li> </ul> </blockquote> </li> <li>For incomplete target words, it is necessary to isolate them in the target word tiers if the target sounds are elicited. See the images below as examples.</li> </ul> </blockquote> <p><em>Example: in ‘西瓜’ if parent says ‘西’, we should tag it in the Target_CL tier. However, if only ‘瓜’ is said, it is not necessary to label it in the Target_CL tier. This would apply to English, Malay and Tamil as well, whereby in Malay if ‘pa’ was said, it should be indicated in the Target_ML tier but there is no need to do so for ‘dang’.</em></p> <p><img src="/belacon/assets/projects/images/t3_targetwords_xigua.png" alt="t3_targetwords_xigua.png" /></p> <p><img src="/belacon/assets/projects/images/t3_targetwords_padang.png" alt="t3_targetwords_padang.png" /></p> <blockquote> <ul> <li>At times, parents might say the plural versions of the target words (e.g. peas, partners). In this case, it is still necessary to isolate them in the target word tiers as the target sounds were elicited.</li> </ul> </blockquote> <p><img src="/belacon/assets/projects/images/t3_targetwords_plural_partners.png" alt="t3_targetwords_plural_partners.png" /></p> <p><img src="/belacon/assets/projects/images/t3_targetwords_plural_peas.png" alt="t3_targetwords_plural_peas.png" /></p> <blockquote> <ul> <li>If target words are spelt out letter by letter i.e. parent says each letter out loud, they <strong>do not need</strong> to be tagged in the target word tiers. When a word is being said out letter by letter, it should be annotated like this: <code class="highlighter-rouge">p... e... a...</code> . Do refer to the example as shown below.</li> </ul> </blockquote> <p><img src="/belacon/assets/projects/images/t3_targetwords_spellingofpea.PNG" alt="t3_targetwords_spellingofpea.PNG" /></p> <blockquote> <ul> <li>Isolate instances (e.g., mention of the baby’s name) that need redacting on the <a href="/belaconBELA/convention/tier-guide.html#sensitive_masking-tier"><code class="highlighter-rouge">Sensitive_Masking</code></a> tier. Live demo on how to use the Sensitive_Masking tier <a href="https://youtu.be/4KScOFyTgK4">here</a>.</li> <li>Use the <code class="highlighter-rouge">Translation</code> tier if you need to translate any non-English utterances into English.</li> </ul> </blockquote> <blockquote> <p>7b. <em>Transcribing the story reading segment</em></p> <ul> <li>Transcribe utterances on the <code class="highlighter-rouge">Utterance</code>, <code class="highlighter-rouge">Chunk</code>, and <code class="highlighter-rouge">Language</code> tiers. Use the <code class="highlighter-rouge">Translation</code> tier if you need to translate any non-English utterances into English.</li> <li>Isolate instances (e.g., mention of the baby’s name) that need redacting on the <a href="/belaconBELA/convention/tier-guide.html#sensitive_masking-tier"><code class="highlighter-rouge">Sensitive_Masking</code></a> tier. Live demo on how to use the Sensitive_Masking tier <a href="https://youtu.be/4KScOFyTgK4">here</a>.</li> <li>What counts as an utterance? Read “A Problem Named Utterance” by Dr. Shamala Sundaray, which can be found <a href="/belacon/assets/projects/TTS/docs/a_problem_named_utterance_20200730.pdf">here</a></li> <li>Utterances directed to the child and researcher should be separate. For instance, the parent may follow up an utterance to the child with a directive to the researcher, e.g., <strong>look at the monkey okay next page what is this</strong>. A part of the utterance is instructions directed to the researcher to flip the page during the storybook sharing task. Hence, it should be transcribed as separate utterances: <strong>look at the monkey, okay next page, what is this.</strong> In general, utterances directed to two different people should be considered as separate utterances. In some cases, prosodic information in the audio file may offer additional information on how to segment the utterance.</li> </ul> </blockquote> </li> <li>Decide how to transcribe speech unrelated to storybook reading and unrelated to PC segments. <ul> <li>There is a difference in transcription protocols and conventions when transcribing utterances related or unrelated to the activities in the audio recording (in this case, storybook reading and PC segments).</li> <li>As a general rule of thumb, we wish to transcribe speech that is observed during the story reading and PC segments to understand how parents engage their children in these shared activities. During these activities, there may be speech that is not related to the activities. Examples: <ul> <li>questions or instructions to researchers (e.g., is the page supposed to turn?, next page),</li> <li>requests to pause the task (e.g., sorry can we pause?),</li> <li>talks to another person (e.g., Mother turning around to talk to Father that came into the room)</li> </ul> </li> <li>For the above scenarios, if the parent remains on screen and does not start a completely new task, speech should be transcribed as per normal.</li> <li>On the other hand, if the parent leaves the screen or starts a completely new task unrelated to story reading or PC, we will partially transcribe the speech as outlined in Step 9 below.</li> <li>In order to decide which conventions should be used, this decision table should be used. If you are still unsure, please check in with any team members for further clarification.</li> </ul> <p><img src="/belacon/assets/projects/images/untranscribed_speech_flowchart.png" alt="untranscribed_speech_flowchart.png" /></p> </li> <li>Partially transcribe speech unrelated to storybook reading or PC segements using the following protocol. <ul> <li>For the portions before the start and after the end of story reading and PC segments of the audio file, if any speaker is talking, mark the onsets and offsets of each utterance.</li> <li>As we only wish to transcribe speech during story reading or PC segments, utterances that occur before the start of story reading (and PC) and utterances that occur after the end of story reading (and PC) should be labelled but do not need to be fully transcribed.</li> <li>Utterances that occur during the transition between activity segments (e.g., from Mandarin PC to storybook or from English PC to Mandarin PC) should also be labelled and do not need to be fully transcribed.</li> <li>If the utterance only contains speech and vocal sounds, demarcate the onset and offset of the utterance. Type <code class="highlighter-rouge">*untranscribed_speech*</code> (with the asterisks) in the Utterance and Chunk tiers. Then, use the Vocal Sounds tag in the Language tier. There is no need to demarcate the onsets and offsets of different languages or vocal sounds for each utterance. If the Baby makes noises/speaks, follow the same procedure in the Utterance and Chunk tiers, and the Language tag is Vocal Sounds as well. This is the only time Vocal Sounds can be used in the Baby (Language) tier.</li> </ul> <p><img src="/belacon/assets/projects/TAT/images/untranscribed_speech_elan_babyname.png" alt="untranscribed_speech_elan_babyname.png" /></p> <ul> <li>If the utterance only contains non-vocal sounds, it should be labelled with the appropriate tags. Example, if there is clapping, <code class="highlighter-rouge">:s:clapping</code> should be enclosed in the Utterance and Chunk tiers, while Non Vocal Sounds should be used in the Language tier. Note that the chime sound that plays when the orangutan storybook pages turn should not be transcribed. Mouse clicks should not be transcribed either. Read our section on non-vocal sounds <a href="/belacon/BELA/convention/special-characters.html#2-non-vocal-sounds">here</a> should you need additional guidance on what non-vocal sounds should be labelled.</li> </ul> <p><img src="/belacon/assets/projects/TAT/images/untranscribed_speech_elan_clapping.png" alt="untranscribed_speech_elan_clapping.png" /></p> <ul> <li>If the utterance contains both non-vocal sounds and speech, the onset and offset of speech and non vocal sounds should be demarcated accordingly. If the chime sound that plays when the orangutan storybook pages turn or mouse clicking sounds happen in between untranscribed speech, there is no need to demarcate them.</li> <li>If you hear names or items to be redacted, isolate these instances the in SENSITIVE_MASKING tiers. Refer to <a href="/belacon/BELA/convention/privacy.html#privacy-matters">this site</a> to see what should be redacted. <ul> <li>If more than one Sensitive_masking tag appears in an utterance, they should be added by order of which they appear. For example, if the Mother says the sibling’s name followed by some words and then the baby’s name, you should transcribe it as: <code class="highlighter-rouge">*untranscribed_speech* SIBLINGNAME BABYNAME</code> in the Utterance and Chunk tier. Then isolate the instances of each name in the SENSITIVE_MASKING tier of the Mother.</li> </ul> </li> </ul> <p><img src="/belacon/assets/projects/TAT/images/untranscribed_speech_elan_siblingname.png" alt="untranscribed_speech_elan_siblingname.png" /></p> <ul> <li><strong>IMPORTANT:</strong> If you are unsure whether to redact an audio region, please consult the team for a second opinion. It’s important for us to ascertain carefully if an audio region should be redacted or not to protect the privacy of our participants.</li> </ul> <p><strong>NOTE:</strong> We recommend future researchers to do Steps 8 and 9 while transcribing the audio file. These steps were done post-hoc when transcribing the Talk Together Study audio files and added into the protocol after. Since July 2023, these steps have been fully integrated into the BLIP lab’s transcription workflow (see Talkathon VCST protocol).</p> </li> <li> <p>Ensure you mark out the start and end of the PC segment and story reading segmentin the recording on the <code class="highlighter-rouge">ActivityMarkers</code> tier. Follow the guidelines in step 1 to get an understanding of where each activity starts and ends. Do consult a full-time staff member should you have any questions.</p> <ul> <li><code class="highlighter-rouge">:marker:start:cds_voweltri_Eng</code> should be used to mark the start of the VCST Picture Cards/Vowel Triangles <strong>English</strong> segment.</li> <li><code class="highlighter-rouge">:marker:end:cds_voweltri_Eng</code> should be used to mark the end of the VCST Picture Cards/Vowel Triangles <strong>English</strong> segment.</li> <li><code class="highlighter-rouge">:marker:start:cds_voweltri_[language name]</code> should be used to mark the start of the VCST Picture Cards/Vowel Triangles <strong>preferred language</strong> segment (i.e., Mandarin, Malay, or Tamil).</li> <li><code class="highlighter-rouge">:marker:end:cds_voweltri_[language name]</code> should be used to mark the end of the VCST Picture Cards/Vowel Triangles <strong>preferred language</strong> segment (i.e., Mandarin, Malay, or Tamil).</li> <li><code class="highlighter-rouge">:marker:start:cds_book</code> should be used to mark the start of the Story Reading segment.</li> <li><code class="highlighter-rouge">:marker:end:cds_book</code> should be used to mark the end of the Story Reading Segment.</li> <li>Watch our video <a href="https://youtu.be/pDTGJypkt8Y">here</a> or the read the <a href="/belacon/BELA/convention/tier-guide.html#activity-marker-tier">activity markers section</a> in our tier guide in this wiki should you need more guidance on how the ActivityMarkers tier works.</li> </ul> </li> <li> <p>Update the transcription log to note your transcription progress on a given file.</p> <p>a) If you’re still working on the file, note “ongoing” in Column J (actual trans. hrs) and add the date and amount of audio transcribed in the 1st or 2nd listen column (Column K and L, respectively).</p> <p>b) If you have finished transcribing a file alert a full-time staff member, update Column J (actual trans. hrs) with the number of hours it took you to complete the transcription, and write the dates of completion of each listen in Column K and L.</p> <p>For more information about each column in the Transcription Log, please refer to <a href="/belacon/Projects/TTS/transcription-log.html">this page</a> in the wiki.</p> </li> </ol> <p>Back to <a href="#contents">table of contents</a></p> </main> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
